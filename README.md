# vLLM-optimization
Benchmarking and optimizing vLLM-based LLM inference on the ORFEO (Area Science Park / LADE) Kubernetes GPU cluster using Locust (performance) and LM Evaluation Harness (accuracy), with automated reporting and tuning experiments.
